# ICRA-2022上SLAM相关论文

## ICRA-2022 SLAM Paper list.

- H. Huang and S.-K. Yeung, “360VO: Visual Odometry Using a Single 360 Camera,” 
  - 全景相机的VO，ETH的大组也做过类似的工作，那篇叫benefit of large field-of-View Cameras for Visual Odometry

- Y. Zhao, X. Zhang, and X. Huang, “A Divide-And-Merge Point Cloud Clustering Algorithm for LiDAR Panoptic Segmentation,” 

- H. Sang, R. Jiang, Z. Wang, Y. Zhou, and B. He, “A Novel Neural Multi-Store Memory Network for Autonomous Visual Navigation in Unknown Environment,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 2039–2046, Apr. 2022, doi: [10.1109/LRA.2022.3140795](https://doi.org/10.1109/LRA.2022.3140795).

- D. Menini, S. Kumar, M. R. Oswald, E. Sandstrom, C. Sminchisescu, and L. Van Gool, “A Real-Time Online Learning Framework for Joint 3D Reconstruction and Semantic Segmentation of Indoor Scenes,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 1332–1339, Apr. 2022, doi: [10.1109/LRA.2021.3138539](https://doi.org/10.1109/LRA.2021.3138539).

- Y. Song, Z. Zhang, J. Wu, Y. Wang, L. Zhao, and S. Huang, “A Right Invariant Extended Kalman Filter for Object Based SLAM,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 1316–1323, Apr. 2022, doi: [10.1109/LRA.2021.3139370](https://doi.org/10.1109/LRA.2021.3139370).

- H. Lim *et al.*, “A Single Correspondence Is Enough: Robust Global Registration to Avoid Degeneracy in Urban Environments,” p. 8.

- F. Eiras, M. Hawasly, S. V. Albrecht, and S. Ramamoorthy, “A Two-Stage Optimization-Based Motion Planner for Safe Urban Driving,” *IEEE Trans. Robot.*, vol. 38, no. 2, pp. 822–834, Apr. 2022, doi: [10.1109/TRO.2021.3088009](https://doi.org/10.1109/TRO.2021.3088009).

- Y. Wang and H. Cheng, “A2DIO: Attention-Driven Deep Inertial Odometry for Pedestrian Localization Based on 6D IMU,” p. 7.
- P. Schutt, R. A. Rosu, and S. Behnke, “Abstract Flow for Temporal Semantic Segmentation on the Permutohedral Lattice,” p. 7.
- R. Tian *et al.*, “Accurate and Robust Object-oriented SLAM with 3D Quadric Landmarks in Outdoors,” p. 7.
- J. Park, Y. Jeong, K. Joo, D. Cho, and I. S. Kweon, “Adaptive Cost Volume Fusion Network for Multi-Modal Depth Estimation in Changing Environments,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 5095–5102, Apr. 2022, doi: [10.1109/LRA.2022.3150868](https://doi.org/10.1109/LRA.2022.3150868).
- Y. Yue, C. Zhao, Y. Wang, Y. Yang, and D. Wang, “Aerial-Ground Robots Collaborative 3D Mapping in GNSS-Denied Environments,” p. 7.
- K. Xu, C. Wang, C. Chen, W. Wu, and S. Scherer, “AirCode: A Robust Object Encoding Method,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 1816–1823, Apr. 2022, doi: [10.1109/LRA.2022.3141221](https://doi.org/10.1109/LRA.2022.3141221).
- Y. Qiu, C. Wang, W. Wang, M. Henein, and S. Scherer, “AirDOS: Dynamic SLAM Benefits from Articulated Objects,” p. 7.
- D. Gao, C. Wang, and S. Scherer, “AirLoop: Lifelong Loop Closure Detection,” p. 8.
- M. Mattamala, N. Chebrolu, and M. Fallon, “An Efficient Locally Reactive Controller for Safe Navigation in Visual Teach and Repeat Missions,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 2353–2360, Apr. 2022, doi: [10.1109/LRA.2022.3143196](https://doi.org/10.1109/LRA.2022.3143196).
- D. Hu, “Approximating the Polynomial System for Effective Relative Pose Estimation,” p. 7.
- M. Frosi and M. Matteucci, “ART-SLAM: Accurate Real-Time 6DoF LiDAR SLAM,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 2692–2699, Apr. 2022, doi: [10.1109/LRA.2022.3144795](https://doi.org/10.1109/LRA.2022.3144795).
- C. Cao *et al.*, “Autonomous Exploration Development Environment and the Planning Algorithms,” p. 8.
- L. Zhang, D. Wisth, M. Camurri, and M. Fallon, “Balancing the Budget: Feature Selection and Tracking for Multi-Camera Visual-Inertial Odometry,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 1182–1189, Apr. 2022, doi: [10.1109/LRA.2021.3137910](https://doi.org/10.1109/LRA.2021.3137910).
- X. Wang, M. Christie, and E. Marchand, “Binary Graph Descriptor for Robust Relocalization on Heterogeneous Data,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 2008–2015, Apr. 2022, doi: [10.1109/LRA.2022.3142854](https://doi.org/10.1109/LRA.2022.3142854).
- X. Xiao, Y. Zhang, H. Li, H. Wang, and B. Li, “Camera-IMU Extrinsic Calibration Quality Monitoring for Autonomous Ground Vehicles,” *IEEE Robot. Autom. Lett.*, vol. 7, no. 2, pp. 4614–4621, Apr. 2022, doi: [10.1109/LRA.2022.3151970](https://doi.org/10.1109/LRA.2022.3151970).
- W.-C. Tseng, H.-J. Liao, Y.-C. Lin, and M. Sun, “CLA-NeRF: Category-Level Articulated Neural Radiance Field,” 
- L. Bernreiter, S. Khattak, L. Ott, R. Siegwart, M. Hutter, and C. C. Lerma, “Collaborative Robot Mapping Using Spectral Graph Analysis,” 
- J. Mo and J. Sattar, “Continuous-Time Spline Visual-Inertial Odometry,”
- G. Cioffi, T. Cieslewski, and D. Scaramuzza, “Continuous-Time Vs. Discrete-Time Vision-Based SLAM: A Comparative Study,” *IEEE Robot. Autom. Lett.*, 
- R. Marcuzzi, L. Nunes, L. Wiesmann, I. Vizzo, J. Behley, and C. Stachniss, “Contrastive Instance Association for 4D Panoptic Segmentation Using Sequences of 3D LiDAR Scans,” *IEEE Robot. Autom. Lett.*,
- Z. Ye, “Crossview Mapping with Graph-Based Geolocalization on City-Scale Street Maps,” 
- P. Dellenbach, J.-E. Deschaud, and B. Jacquet, “CT-ICP: Real-Time Elastic LiDAR Odometry with Loop Closure,” 
- “DA-LMR: A Robust Lane Marking Representation for Data Association,” 
- P. Gao, S. Zhang, W. Wang, and C. X. Lu, “DC-Loc: Accurate Automotive Radar Based Metric Localization with Explicit Doppler Compensation,” 
- S. A. Widjaja, N. Camous, T. M. Bonanni, and V. E. Liong, “Deep Networks for Point Cloud Map Validation,” 
- W. Du, “Depth Completion Using Geometry-Aware Embedding,” 
- L. Jing *et al.*, “Depth Estimation Matters Most: Improving Per-Object Depth Estimation for Monocular 3D Detection and Tracking,” 
- K. Chen, B. T. Lopez, A. Agha-mohammadi, and A. Mehta, “Direct LiDAR Odometry: Fast Localization With Dense Point Clouds,” *IEEE Robot. Autom. Lett.*
- Y. Huang, T. Shan, F. Chen, and B. Englot, “DiSCo-SLAM: Distributed Scan Context-Enabled Multi-Robot LiDAR SLAM With Two-Stage Global-Local Graph Optimization,” *IEEE Robot. Autom. Lett.*, 
- L. Quan, L. Yin, C. Xu, and F. Gao, “Distributed Swarm Trajectory Optimization for Formation Flight in Dense Environments,” 
- L. von Stumberg and D. Cremers, “DM-VIO: Delayed Marginalization Visual-Inertial Odometry,” *IEEE Robot. Autom. Lett.*,
- R. Dempster, M. Alsharman, Y. Jain, J. Li, D. Rayside, and W. Melek, “DRG: A Dynamic Relation Graph for Unified Prior-Online Environment Modeling in Urban Autonomous Driving,” 
- T. Fan, B. Shen, H. Chen, W. Zhang, and J. Pan, “DynamicFilter: An Online Dynamic Objects Removal Framework for Highly Dynamic Environments,”
- L. Zhou, G. Huang, Y. Mao, S. Wang, and M. Kaess, “EDPLVO: Efficient Direct Point-Line Visual Odometry,” 
- D. Seichter, P. Langer, T. Wengefeld, B. Lewandowski, D. Hoechemer, and H.-M. Gross, “Efficient and Robust Semantic Mapping for Indoor Environments,” 
- N. Vodisch, O. Unal, K. Li, L. Van Gool, and D. Dai, “End-to-End Optimization of LiDAR Beam Configuration for 3D Object Detection and Localization,” *IEEE Robot. Autom. Lett.*
- Y. Choe, J. H. Jung, and C. G. Park, “Ensemble Kalman Filter Based LiDAR Odometry for Skewed Point Clouds Using Scan Slicing,” 
- L. Jarin-Lipschitz, X. Liu, Y. Tao, and V. Kumar, “Experiments in Adaptive Replanning for Fast Autonomous Flight in Forests,”
- Y. Zhang, B. Zhou, L. Wang, and S. Shen, “Exploration with Global Consistency Using Real-Time Re-Integration and Active Loop Closure,” 
- S. Das, N. K. Mahabadi, A. Djikic, C. Nassir, S. Chatterjee, and M. Fallon, “Extrinsic Calibration and Verification of Multiple Non-Overlapping Field of View Lidar Sensors,” 
- E. Arnold, S. Mozaffari, and M. Dianati, “Fast and Robust Registration of Partially Overlapping Point Clouds,” *IEEE Robot. Autom. Lett.*
- X. Yang, Y. Ming, Z. Cui, and A. Calway, “FD-SLAM: 3-D Reconstruction Using Features and Dense Matching,”
- C. Chen, Y. Yang, P. Geneva, and G. Huang, “FEJ2: A Consistent Visual-Inertial State Estimator Design,” 
- V. Guizilini, I. Vasiljevic, R. Ambrus, G. Shakhnarovich, and A. Gaidon, “Full Surround Monodepth From Multiple Cameras,” *IEEE Robot. Autom. Lett.*,
- G. Wang, J. Qiu, Y. Guo, and H. Wang, “FusionNet: Coarse-To-Fine Extrinsic Calibration Network of LiDAR and Camera with Hierarchical Point-pixel Fusion,” 
- X. Wei, J. Lv, J. Sun, E. Dong, and S. Pu, “GCLO: Ground Constrained LiDAR Odometry with Low-Drifts for GPS-Denied Indoor Environments,” 
- K. Koide, M. Yokozuka, S. Oishi, and A. Banno, “Globally Consistent and Tightly Coupled 3D LiDAR Inertial Mapping,” 
- Y. Litman, D. McGann, E. Dexheimer, and M. Kaess, “GPS-Denied Global Visual-Inertial Ground Vehicle State Estimation Via Image Registration,” 
- J. Nubert, S. Khattak, and M. Hutter, “Graph-Based Multi-Sensor Fusion for Consistent Localization of Autonomous Construction Robots,” 
- S. Cao, X. Lu, and S. Shen, “GVINS: Tightly Coupled GNSS–Visual–Inertial Fusion for Smooth and Consistent State Estimation,” *IEEE Trans. Robot.*, 
- D. Bai, T. Cao, J. Guo, and B. Liu, “How to Build a Curb Dataset with LiDAR Data for Autonomous Driving,” 
- L. Kã, “Human-Following and -Guiding in Crowded Environments Using Semantic Deep-Reinforcement-Learning for Mobile Service Robots,” 
- Y. Kwon, M. Sung, and S. Yoon, “Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction,” 
- J. Ortiz, T. Evans, E. A. S. Escamilla, and A. J. Davison, “Incremental Abstraction in Distributed Probabilistic SLAM Graphs,” 
- E. Dexheimer, P. Peluse, J. Chen, J. Pritts, and M. Kaess, “Information-Theoretic Online Multi-Camera Extrinsic Calibration,” *IEEE Robot. Autom. Lett.*,
- H. Liu, J. Qiu, and W. Huang, “Integrating Point and Line Features for Visual-Inertial Initialization,” 
- A. Ehambram, R. Voges, C. Brenner, and B. Wagner, “Interval-Based Visual-Inertial LiDAR SLAM with Anchoring Poses,” 
- Y.-K. Lin, W.-C. Lin, and C.-C. Wang, “K-Closest Points and Maximum Clique Pruning for Efficient and Effective 3-D Laser Scan Matching,” *IEEE Robot. Autom. Lett.*
- M. Gridseth and T. D. Barfoot, “Keeping an Eye on Things: Deep Learned Features for Long-Term Visual Localization,” *IEEE Robot. Autom. Lett.*
- J. Zhang, Q. Lyu, G. Peng, Z. Wu, Q. Yan, and D. Wang, “LB-L2L-Calib: Accurate and Robust Extrinsic Calibration for Multiple 3D LiDARs with Long Baseline and Large Viewpoint Difference,” 
- J.-N. Zaech, A. Liniger, D. Dai, M. Danelljan, and L. Van Gool, “Learnable Online Graph Representations for 3D Multi-Object Tracking,” *IEEE Robot. Autom. Lett.*
- T. Zhang and M. Johnson-Roberson, “Learning Cross-Scale Visual Representations for Real-Time Image Geo-Localization,” *IEEE Robot. Autom. Lett.*,
- T.-H. Wang, A. Amini, W. Schwarting, I. Gilitschenski, S. Karaman, and D. Rus, “Learning Interactive Driving Policies Via Data-Driven Simulation,” 
- V. Guizilini, K.-H. Lee, R. Ambrus, and A. Gaidon, “Learning Optical Flow, Depth, and Scene Flow Without Real-World Labels,” *IEEE Robot. Autom. Lett.*
- D. D. Fan, A. Agha-mohammadi, and E. A. Theodorou, “Learning Risk-Aware Costmaps for Traversability in Challenging Environments,” *IEEE Robot. Autom. Lett.*
- H. Thomas, “Learning Spatiotemporal Occupancy Grid Maps for Lifelong Navigation in Dynamic Scenes,”
- B. Xu, P. Wang, Y. He, Y. Chen, Y. Chen, and M. Zhou, “Leveraging Structural Information to Improve Point Line Visual-Inertial Odometry,” *IEEE Robot. Autom. Lett.*
- R. McCraith, E. Insafutdinov, N. Lukas, and A. Vedaldi, “Lifting 2D Object Locations to 3D by Discounting LiDAR Outliers across Objects and Views,” 
- C. Qu, S. Skandan, W. Liu, and C. J. Taylor, “LLOL: Low-Latency Odometry for Spinning Lidars,” 
- S. Mishra *et al.*, “Localization of a Smart Infrastructure Fisheye Camera in a Prior Map for Autonomous Vehicles,”
- K. Vidanapathirana, M. Ramezani, P. Moghadam, S. Sridharan, and C. Fookes, “LoGG3D-Net: Locally Guided Global Descriptor Learning for 3D Place Recognition,”
- A. Papadimitriou *et al.*, “Loop Closure Detection and SLAM in Vineyards with Deep Semantic Cues,” 
- H. Osman, N. Darwish, and A. Bayoumi, “LoopNet: Where to Focus? Detecting Loop Closures in Dynamic Scenes,” *IEEE Robot. Autom. Lett.*
- G. Kim and A. Kim, “LT-Mapper: A Modular Framework for LiDAR-Based Lifelong Mapping,” 
- H. Wang, C. Xue, and Y. Tang, “LTSR: Long-Term Semantic Relocalization Based on HD Map for Autonomous Vehicles,” 
- J. Yin, A. Li, T. Li, W. Yu, and D. Zou, “M2DGR: A Multi-Sensor and Multi-Scenario SLAM Dataset for Ground Robots,” *IEEE Robot. Autom. Lett.*
- P. Z. X. Li, S. Karaman, and V. Sze, “Memory-Efficient Gaussian Fitting for Depth Images in Real Time,” 
- S. Kim, M. Poggi, S. Kim, K. Sohn, and S. Mattoccia, “Meta-Confidence Estimation for Stereo Matching,” 
- K. Zywanowski, A. Banaszczyk, M. R. Nowicki, and J. Komorowski, “MinkLoc3D-SI: 3D LiDAR Place Recognition With Sparse Convolutions, Spherical Coordinates, and Intensity,” *IEEE Robot. Autom. Lett.*
- C. Wang, Y.-P. Wang, and D. Manocha, “MotionHint: Self-Supervised Monocular Visual Odometry with Motion Constraints,” 
- J. P. Company-Corcoles, E. Garcia-Fidalgo, and A. Ortiz, “MSC-VO: Exploiting Manhattan and Structural Constraints for Visual Odometry,” *IEEE Robot. Autom. Lett.*
- A. Palffy, E. Pool, S. Baratam, J. F. P. Kooij, and D. M. Gavrila, “Multi-Class Road User Detection With 3+1D Radar in the View-of-Delft Dataset,” *IEEE Robot. Autom. Lett.*
- D. Braun, O. Morel, and P. Vasseur, “N-QGN: Navigation Map from a Monocular Camera Using Quadtree Generating Networks,” 
- L. Wang, H. Xu, Y. Zhang, and S. Shen, “Neither Fast nor Slow: How to Fly Through Narrow Tunnels,” *IEEE Robot. Autom. Lett.*, 
- Y. Ren, S. Zhao, and B. Liu, “Object Insertion Based Data Augmentation for Semantic Segmentation,” 
- Y. Cho, G. Kim, S. Lee, and J.-H. Ryu, “OpenStreetMap-Based LiDAR Global Localization in Urban Environment Without a Prior LiDAR Map,” *IEEE Robot. Autom. Lett.*
- C. Min and W. Jiang, “ORFD: A Dataset and Benchmark for Off-Road Freespace Detection,”
- J. McConnell, F. Chen, and B. Englot, “Overhead Image Factors for Underwater Sonar-Based SLAM,” *IEEE Robot. Autom. Lett.*, 
- A. Arun, R. Ayyalasomayajula, W. Hunter, and D. Bharadia, “P2SLAM: Bearing Based WiFi SLAM for Indoor Robots,” *IEEE Robot. Autom. Lett.*
- L. M. Schmid *et al.*, “Panoptic Multi-TSDFs: A Flexible Representation for Online Multi-Resolution Volumetric Mapping and Long-Term Dynamic Scene Consistency,” 
- W. K. Fong *et al.*, “Panoptic Nuscenes: A Large-Scale Benchmark for LiDAR Panoptic Segmentation and Tracking,” *IEEE Robot. Autom. Lett.*
- H. Kumar, J. J. Payne, M. Travers, A. M. Johnson, and H. Choset, “Periodic SLAM: Using Cyclic Constraints to Improve the Performance of Visual-Inertial SLAM on Legged Robots,” 
- T. Wen, Y. Zhang, and N. Freris, “PF-MOT: Probability Fusion Based 3D Multi-Object Tracking for Autonomous Vehicles,”
- M. Liu *et al.*, “Prototype-Voxel Contrastive Learning for LiDAR Point Cloud Panoptic Segmentation,” 
- P. Kim, H. Li, and K. Joo, “Quasi-Globally Optimal and Real-Time Visual Compass in Manhattan Structured Environments,” *IEEE Robot. Autom. Lett.*
- S. Wang, J. Jiao, P. Cai, and L. Wang, “R-PCC: A Baseline for Range Image-Based Point Cloud Compression,” 
- J. Lin and F. Zhang, “R3LIVE: A Robust, Real-Time, RGB-Colored, LiDAR-Inertial-Visual Tightly-Coupled State Estimation and Mapping Package,” 
- F. Duerr and H. Weigel, “RangeBird: Multi View Panoptic Segmentation of 3D Point Clouds with Neighborhood Attention,”
- Z. Zou *et al.*, “Real-Time Full-Stack Traffic Scene Perception for Autonomous Driving with Roadside Cameras,” 
- J. Cheng, Y. Chen, Q. Zhang, L. Gan, C. Liu, and M. Liu, “Real-Time Trajectory Planning for Autonomous Driving with Gaussian Process and Incremental Refinement,” 
- Y.-C. Shih, W.-H. Liao, W.-C. Lin, S.-K. Wong, and C.-C. Wang, “Reconstruction and Synthesis of Lidar Point Clouds of Spray,” *IEEE Robot. Autom. Lett.*
- Y. Shi, S. Li, X. Jia, and J. Liu, “Refactoring ISP for High-Level Vision Tasks,” 
- L. Wiesmann, R. Marcuzzi, C. Stachniss, and J. Behley, “Retriever: Point Cloud Retrieval in Compressed 3D Maps,” 
- R. Battrawy, “RMS-FlowNet: Efficient and Robust Multi-Scale Scene Flow Estimation for Large-Scale Point Clouds,” 
- J. Liu, K. Chen, R. Liu, Y. Yang, Z. Wang, and J. Zhang, “Robust and Accurate Multi-Agent SLAM with Efficient Communication for Smart Mobiles,” 
- K. Petek, K. Sirohi, D. Buscher, and W. Burgard, “Robust Monocular Localization in Sparse HD Maps Leveraging Multi-Task Uncertainty Estimation,” 
- Y. Xu, J. Lin, J. Shi, G. Zhang, X. Wang, and H. Li, “Robust Self-Supervised LiDAR Odometry Via Representative Structure Discovery and 3D Inherent Error Modeling,” *IEEE Robot. Autom. Lett.*, 
- J. Yuan, J. Hong, J. Sattar, and V. Isler, “ROW-SLAM: Under-Canopy Cornfield Semantic SLAM,” 
- K. Sun, S. Chaves, P. Martin, and V. Kumar, “RTGNN: A Novel Approach to Model Stochastic Traffic Dynamics,” 
- M. Vitelli, Y. Chang, Y. Ye, A. S. R. Ferreira, and M. Wo, “SafetyNet: Safe Planning for Real-World Self-Driving Vehicles Using Machine Learned Policies,” 
- L. Nunes, R. Marcuzzi, X. Chen, J. Behley, and C. Stachniss, “SegContrast: 3D Point Cloud Feature Representation Learning through Self-Supervised Segment Discrimination,”
- U. Shin, K. Lee, S. Lee, and I. S. Kweon, “Self-Supervised Depth and Ego-Motion Estimation for Monocular Thermal Video Using Multi-Spectral Consistency Loss,” *IEEE Robot. Autom. Lett.*,
- Z. Jiang, H. Taira, N. Miyashita, and M. Okutomi, “Self-Supervised Ego-Motion Estimation Based on Multi-Layer Fusion of RGB and Inferred Depth,” 
- J. Choi *et al.*, “SelfTune: Metrically Scaled Monocular Depth Estimation throughSelf-Supervised Learning,” 
- S. Liang, Y. Zhang, R. Tian, D. Zhu, L. Yang, and Z. Cao, “SemLoc: Accurate and Robust Visual Localization with Semantic and Structural Constraints from Prior Maps,” 
- U.-H. Kim, S.-H. Kim, and J.-H. Kim, “SimVODIS++: Neural Semantic Visual Odometry in Dynamic Environments,” *IEEE Robot. Autom. Lett.*
- E. Li, R. Razani, Y. Xu, and B. Liu, “SMAC-Seg: LiDAR Panoptic Segmentation Via Sparse Multi-Directional Attention Clustering,” 
- Z. Liao, Y. Hu, J. Zhang, X. Qi, X. Zhang, and W. Wang, “SO-SLAM: Semantic Object SLAM With Scale Proportional and Symmetrical Texture Constraints,” *IEEE Robot. Autom. Lett.*
- W. G. C. Bandara, J. M. J. Valanarasu, and V. Patel, “SPIN Road Mapper: Extracting Roads from Aerial Images Via Spatial and Interaction Space Graph Reasoning for Autonomous Driving,”
- W. Lee, P. Geneva, Y. Yang, and G. Huang, “Tightly-Coupled GNSS-Aided Visual-Inertial Localization,” 
- J. Coulin, R. Guillemard, V. Gay-Bellile, C. Joly, and A. de L. Fortelle, “Tightly-Coupled Magneto-Visual-Inertial Fusion for Long Term Localization in Indoor Environment,” *IEEE Robot. Autom. Lett.*
- Z. Qian, J. Fu, and J. Xiao, “Towards Accurate Loop Closure Detection in Semantic SLAM With 3D Semantic Covisibility Graphs,” *IEEE Robot. Autom. Lett.*
- S. Zhang, J. Zhang, and D. Tao, “Towards Scale Consistent Monocular Visual Odometry by Learning from the Virtual World,” 
- J. Xu, L. Xiao, D. Zhao, Y. Nie, and B. Dai, “Trajectory Prediction for Autonomous Driving with Topometric Map,”
- A. Saha, O. A. M. Maldonado, C. Russell, and R. Bowden, “Translating Images into Maps,” 
- D. Paz, H. Xiang, A. Liang, and H. I. Christensen, “TridentNetV2: Lightweight Graphical Global Plan Representations for Dynamic Trajectory Generation,” 
- H. Lim, J. Jeon, and H. Myung, “UV-SLAM: Unconstrained Line-Based SLAM Using Vanishing Points for Structural Mapping,” *IEEE Robot. Autom. Lett.*
- Q. Cheng, N. Zeller, and D. Cremers, “Vision-Based Large-Scale 3D Semantic Mapping for Autonomous Driving Applications,” 
- M. Adamkiewicz *et al.*, “Vision-Only Robot Navigation in a Neural Radiance World,” *IEEE Robot. Autom. Lett.*
- R. Mascaro, L. Teixeira, and M. Chli, “Volumetric Instance-Level Semantic Mapping Via Multi-View 2D-to-3D Label Diffusion,” *IEEE Robot. Autom. Lett.*